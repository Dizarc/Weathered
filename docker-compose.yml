services:
  weathered:
    build:
      context: .
      dockerfile: weathered.dockerfile

    container_name: weathered-app
    restart: unless-stopped
    env_file: "docker.env"
    
    devices:
      - "/dev/dri:/dev/dri" # GPU access
      
    environment:
      - QT_QPA_PLATFORM=eglfs
      - API_KEY=${API_KEY}
      - API_CITY_COUNTRY=${API_CITY_COUNTRY}
      - LM_URL=http://llama-server:8080/v1/chat/completions

    networks:
      - weathered-net
    
  llama-server:
    build:
      context: .
      dockerfile: llama.dockerfile
    
    container_name: llama-server-api
    restart: unless-stopped
    env_file: "docker.env"

    ports:
      - "8080:8080"

    volumes:
      - ${MODEL_PATH}:/app/model.gguf

    networks:
      - weathered-net

networks:
  weathered-net:
    driver: bridge
