# For development workflow.
# Build Qt once and code can be ran instantly through the dev compose by running make inside the container.
services:
  weathered:
    build:
      context: ..
      dockerfile: docker/Dockerfile
      target: app-builder 

    container_name: weathered-app-dev
    
    command: tail -f /dev/null
    
    # If you're running from linux uncomment devices
    #devices:
      #- "/dev/dri:/dev/dri" # GPU access
      
    environment:
      #- DISPLAY=${DISPLAY:-:0} # For display in Linux
      - DISPLAY=host.docker.internal:0.0 # For display in Windows through VcXsrv
      - QT_QPA_PLATFORM_PLUGIN_PATH=/opt/Qt6.8/plugins
      - LD_LIBRARY_PATH=/opt/Qt6.8/lib

      - WEATHER_API_KEY=${WEATHER_API_KEY}
      - WEATHER_API_CITY_COUNTRY=${WEATHER_API_CITY_COUNTRY}
      - NEWS_API_KEY=${NEWS_API_KEY}
      - LM_URL=http://llama-server:8080/v1/chat/completions

    volumes:
      - /tmp/.X11-unix:/tmp/.X11-unix:rw # For display
      - ..:/app

    networks:
      - weathered-net
    
  llama-server:
    image: ghcr.io/ggml-org/llama.cpp:server
    
    container_name: llama-server-api
    restart: unless-stopped

    ports:
      - "8080:8080"

    volumes:
      - ${MODEL_PATH}:/models/model.gguf

    command: ["-m", "/models/model.gguf", "--host", "0.0.0.0", "--port", "8080", "--n-gpu-layers", "0"]

    networks:
      - weathered-net

networks:
  weathered-net:
    driver: bridge
