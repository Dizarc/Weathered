# For development workflow.
# Build Qt once and code can be ran instantly through the dev compose by running make inside the container.
services:
  weathered:
    build:
      context: .
      dockerfile: weathered.dockerfile

    container_name: weathered-app-dev

    command: tail -f /dev/null
    
    devices:
      - "/dev/dri:/dev/dri" # GPU access
      
    environment:
      - DISPLAY=${DISPLAY} # For display
      - API_KEY=${API_KEY}
      - API_CITY_COUNTRY=${API_CITY_COUNTRY}
      - LM_URL=http://llama-server:8080/v1/chat/completions

    volumes:
      - /tmp/./X11-unix:/tmp/.X11-unix:rw # For display
      - .:/app

    networks:
      - weathered-net
    
  llama-server:
    build:
      context: .
      dockerfile: llama.dockerfile
    
    container_name: llama-server-api
    restart: unless-stopped

    ports:
      - "8080:8080"

    volumes:
      - ${MODEL_PATH}:/app/model.gguf

    networks:
      - weathered-net

networks:
  weathered-net:
    driver: bridge
